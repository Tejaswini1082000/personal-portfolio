export const experienceData = [
  {
    title: "Data Analyst",
    company: "Mr Cooper",
    period: "09/2024 – present",
    location: "TX, USA",
    responsibilities: [
      "Collected, cleaned, and analyzed data from sources like Excel, SQL databases, and CSV files to support business reporting and decision-making.",
      "Created interactive dashboards and visualizations using Power BI and Tableau to communicate trends and KPIs to non-technical stakeholders.",
      "Wrote SQL queries and used Python (Pandas, NumPy) for data manipulation, validation, and exploratory data analysis.",
      "Assisted in building automated reports and scheduled data refreshes using tools like Power BI, Azure Data Factory, and Excel macros."
    ],
    techStack: "Power BI, Tableau, Excel, SQL, Python (Pandas, NumPy), Azure Data Factory, CSV, Excel Macros, Azure SQL Database"
  },
  {
    title: "System Engineer",
    company: "Infosys Limited",
    period: "11/2021 – 07/2023",
    location: "Hyderabad, India",
    responsibilities: [
      "Developed and maintained backend components using Java and Spring, optimizing microservices and RESTful APIs for performance and scalability. Resolved bugs and implemented UI enhancements to improve functionality.",
      "Monitored and troubleshot Java-based applications using Splunk and AppDynamics, addressing exceptions, memory leaks, and performance bottlenecks. Conducted root cause analysis (RCA) to prevent recurring issues.",
      "Deployed applications via Bamboo CI/CD, managed Bitbucket/Git repositories, and ensured code quality through reviews and best practices.",
      "Collaborated with cross-functional teams to resolve issues, deploy features, and document technical processes (AID, RCA reports). Provided mentorship on debugging and troubleshooting system."
    ],
    techStack: "Spring Tool Suite(STS), Java, HTML, CSS, Bamboo, Bitbucket, Jira, Confluence, Cherwell, Splunk"
  },
  {
    title: "Machine Learning Intern",
    company: "IBM",
    period: "05/2020 – 06/2020",
    location: "Remote",
    responsibilities: [
      "Gathered, cleaned, and preprocessed datasets from Kaggle, ensuring data integrity for analysis. Enhanced data processing pipelines using Python Pandas, reducing transformation time by 40% and improving system efficiency.",
      "Deployed Decision Trees, Random Forests, and Neural Networks in a distributed environment, cutting prediction latency by 30% and enhancing real-time decision-making.",
      "Utilized Matplotlib & Seaborn to visualize system performance, identifying CPU and memory bottlenecks, leading to a 25% improvement in query execution efficiency.",
      "Developed predictive models for anomaly detection, achieving an R² value of 0.82 and reducing false alerts by 20% in production system monitoring."
    ],
    techStack: "Python, Pandas, Scikit-learn, TensorFlow, Matplotlib & Seaborn"
  }
];